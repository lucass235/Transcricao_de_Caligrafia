{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação dos dados\n",
    "import os\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchsummaryX import summary\n",
    "\n",
    "from mltu.torch.model import Model\n",
    "from mltu.torch.losses import CTCLoss\n",
    "from mltu.torch.dataProvider import DataProvider\n",
    "from mltu.torch.metrics import CERMetric, WERMetric\n",
    "from mltu.torch.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, Model2onnx, ReduceLROnPlateau\n",
    "\n",
    "from mltu.preprocessors import ImageReader\n",
    "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding, ImageShowCV2\n",
    "from mltu.augmentors import RandomBrightness, RandomRotate, RandomErodeDilate, RandomSharpen\n",
    "from mltu.annotations.images import CVImage\n",
    "\n",
    "from handwriting_recognition_torch.model import Network\n",
    "from handwriting_recognition_torch.configs import ModelConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26253 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26253/26253 [00:00<00:00, 27373.97it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset, vocab, max_len = [], set(), 0\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # image = CVImage(row['image'])\n",
    "    label = row['Label']\n",
    "    path_image = row['ID']\n",
    "    dataset.append((path_image, label))\n",
    "    vocab.update(list(label))\n",
    "    max_len = max(max_len, len(label))\n",
    "    \n",
    "configs = ModelConfigs()\n",
    "configs.model_path = os.path.join( \"./Models/\")\n",
    "configs.train_epochs = 10\n",
    "configs.vocab = \"\".join(sorted(vocab))\n",
    "configs.max_text_length = max_len    \n",
    "configs.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" '()+,-.0123456789:<=>ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzÁÂÃÇÉÊÍÓÔÕÚáãäçéêíóöüćčšе‘√✓\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 15:21:01,757 INFO DataProvider: Skipping Dataset validation...\n"
     ]
    }
   ],
   "source": [
    "# Criação do modelo e definição dos hiperparâmetros\n",
    "data_provider = DataProvider(\n",
    "    dataset=dataset,\n",
    "    skip_validation=True,\n",
    "    batch_size=configs.batch_size,\n",
    "    data_preprocessors=[ImageReader(CVImage)],\n",
    "    transformers=[\n",
    "        # ImageShowCV2(),  # uncomment to show images when iterating over the data provider\n",
    "        ImageResizer(configs.width, configs.height, keep_aspect_ratio=False),\n",
    "        LabelIndexer(configs.vocab),\n",
    "        LabelPadding(max_word_length=configs.max_text_length,\n",
    "                     padding_value=len(configs.vocab))\n",
    "    ],\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão do dataset em treino e teste (90% e 10%)\n",
    "train_dataProvider, test_dataProvider = data_provider.split(split = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train_dataProvider.augmentors = [\n",
    "    RandomBrightness(), \n",
    "    RandomErodeDilate(),\n",
    "    RandomSharpen(),\n",
    "    RandomRotate(angle=10), \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network(len(configs.vocab), activation=\"leaky_relu\", dropout=0.3)\n",
    "loss = CTCLoss(blank=len(configs.vocab))\n",
    "optimizer = optim.Adam(network.parameters(), lr=configs.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do callback para o treinamento\n",
    "earlyStopping = EarlyStopping(monitor=\"val_CER\", patience=20, mode=\"min\", verbose=1)\n",
    "modelCheckpoint = ModelCheckpoint(configs.model_path + \"/model.pt\", monitor=\"val_CER\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "tb_callback = TensorBoard(configs.model_path + \"/logs\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_CER\", factor=0.9, patience=10, verbose=1, mode=\"min\", min_lr=1e-6)\n",
    "model2onnx = Model2onnx(\n",
    "    saved_model_path=configs.model_path + \"/model.pt\",\n",
    "    input_shape=(1, configs.height, configs.width, 3), \n",
    "    verbose=1,\n",
    "    metadata={\"vocab\": configs.vocab}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/370 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lucas\\Documents\\GitHub\\Transcricao_de_Caligrafia\\manuscrito_alunos\\train.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Criação do modelo para o treinamento\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m Model(network, optimizer, loss, metrics\u001b[39m=\u001b[39m[CERMetric(configs\u001b[39m.\u001b[39mvocab), WERMetric(configs\u001b[39m.\u001b[39mvocab)])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_dataProvider, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     test_dataProvider, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[earlyStopping, modelCheckpoint, tb_callback, reduce_lr, Model2onnx(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         saved_model_path\u001b[39m=\u001b[39;49mconfigs\u001b[39m.\u001b[39;49mmodel_path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/model.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         input_shape\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, configs\u001b[39m.\u001b[39;49mheight, configs\u001b[39m.\u001b[39;49mwidth, \u001b[39m3\u001b[39;49m), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         metadata\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mvocab\u001b[39;49m\u001b[39m\"\u001b[39;49m: configs\u001b[39m.\u001b[39;49mvocab},\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         opset_version\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     )]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lucas/Documents/GitHub/Transcricao_de_Caligrafia/manuscrito_alunos/train.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mltu\\torch\\model.py:244\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, train_dataProvider, test_dataProvider, epochs, initial_epoch, callbacks)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(initial_epoch, initial_epoch \u001b[39m+\u001b[39m epochs):\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m--> 244\u001b[0m     train_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(train_dataProvider)\n\u001b[0;32m    245\u001b[0m     val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest(test_dataProvider)\n\u001b[0;32m    247\u001b[0m     logs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_logs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mval_logs}\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mltu\\torch\\model.py:151\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, dataProvider)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mon_batch_begin(step, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    150\u001b[0m data, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoDevice(\u001b[39m*\u001b[39mtoTorch(data, target))\n\u001b[1;32m--> 151\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(data, target)\n\u001b[0;32m    152\u001b[0m loss_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    153\u001b[0m loss_mean \u001b[39m=\u001b[39m loss_sum \u001b[39m/\u001b[39m step\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mltu\\torch\\model.py:108\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data, target)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    106\u001b[0m \u001b[39m# torch.cuda.synchronize() # synchronize after each forward and backward pass\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39;49mupdate(target, output)\n\u001b[0;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mltu\\torch\\handlers.py:23\u001b[0m, in \u001b[0;36mMetricsHandler.update\u001b[1;34m(self, target, output)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(\u001b[39mself\u001b[39m, target, output):\n\u001b[0;32m     22\u001b[0m     \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics:\n\u001b[1;32m---> 23\u001b[0m         metric\u001b[39m.\u001b[39;49mupdate(output, target)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mltu\\torch\\metrics.py:107\u001b[0m, in \u001b[0;36mCERMetric.update\u001b[1;34m(self, output, target)\u001b[0m\n\u001b[0;32m    104\u001b[0m output_texts \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocabulary[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m group \u001b[39mif\u001b[39;00m k \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocabulary)]) \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m grouped_preds]\n\u001b[0;32m    105\u001b[0m target_texts \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocabulary[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m group \u001b[39mif\u001b[39;00m k \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocabulary)]) \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m target]\n\u001b[1;32m--> 107\u001b[0m cer \u001b[39m=\u001b[39m get_cer(output_texts, target_texts)\n\u001b[0;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcer \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m cer\n\u001b[0;32m    110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcounter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mltu\\utils\\text_utils.py:73\u001b[0m, in \u001b[0;36mget_cer\u001b[1;34m(preds, target)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_cer\u001b[39m(\n\u001b[0;32m     61\u001b[0m     preds: typing\u001b[39m.\u001b[39mUnion[\u001b[39mstr\u001b[39m, typing\u001b[39m.\u001b[39mList[\u001b[39mstr\u001b[39m]],\n\u001b[0;32m     62\u001b[0m     target: typing\u001b[39m.\u001b[39mUnion[\u001b[39mstr\u001b[39m, typing\u001b[39m.\u001b[39mList[\u001b[39mstr\u001b[39m]],\n\u001b[0;32m     63\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m     64\u001b[0m     \u001b[39m\"\"\" Update the cer score with the current set of references and predictions.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39m        Character error rate score\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     preds \u001b[39m=\u001b[39m preds\u001b[39m.\u001b[39;49msplit()\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(target, \u001b[39mfloat\u001b[39m):\n\u001b[0;32m     75\u001b[0m         target \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(target)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# Criação do modelo para o treinamento\n",
    "model = Model(network, optimizer, loss, metrics=[CERMetric(configs.vocab), WERMetric(configs.vocab)])\n",
    "model.fit(\n",
    "    train_dataProvider, \n",
    "    test_dataProvider, \n",
    "    epochs=10, \n",
    "    callbacks=[earlyStopping, modelCheckpoint, tb_callback, reduce_lr, Model2onnx(\n",
    "        saved_model_path=configs.model_path + \"/model.pt\",\n",
    "        input_shape=(1, configs.height, configs.width, 3), \n",
    "        verbose=1,\n",
    "        metadata={\"vocab\": configs.vocab},\n",
    "        opset_version=10\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training and validation datasets as csv files\n",
    "train_dataProvider.to_csv(os.path.join(\"./\", \"train.csv\"))\n",
    "test_dataProvider.to_csv(os.path.join(\"./\", \"val.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testar com uma imagem\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from keras.models import load_model\n",
    "\n",
    "# # Carrega o modelo treinado\n",
    "# model = load_model(configs.model_path + \"/model.hdf5\")\n",
    "\n",
    "# # Carrega a imagem\n",
    "# image = cv2.imread(\"../data/iam_data/words/a01/a01-000u/a01-000u-00-00.png\")\n",
    "\n",
    "# # Pré-processa a imagem\n",
    "# image = cv2.resize(image, (configs.image_size, configs.image_size))\n",
    "# image = image.astype(\"float\") / 255.0\n",
    "# image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# # Faz a previsão na imagem\n",
    "# prediction = model.predict(image)\n",
    "\n",
    "# # Imprime a previsão\n",
    "# print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
